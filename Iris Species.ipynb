{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Pooja-Shanbhag/Predicting-Iris-Flower-Species/blob/master/Iris%20Species.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.optim import SGD\n",
    "from numpy import vstack\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self,path):\n",
    "        dataframe = read_csv(path,header = None)\n",
    "        self.X = dataframe.values[:,:-1]\n",
    "        self.X = self.X.astype('float32')\n",
    "        self.y = dataframe.values[:,-1]\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "        self.y = self.y.reshape(len(self.y),1)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        return [self.X[idx],self.y[idx]]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def split_data(self, n_train = 0.67):\n",
    "        train_len = round(len(self.X)*n_train)\n",
    "        test_len = len(self.X) - train_len\n",
    "        return random_split(self, [train_len,test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Module):\n",
    "    def __init__(self,inputs):\n",
    "        super(MLP,self).__init__()\n",
    "        self.hidden1 = Linear(inputs, 10)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity = 'relu')\n",
    "        self.act1 = ReLU()\n",
    "        \n",
    "        self.hidden2 = Linear(10,8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity = 'relu')\n",
    "        self.act2 = ReLU()\n",
    "        \n",
    "        self.hidden3 = Linear(8,3)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Sigmoid()\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path):\n",
    "    dataset = CSVDataset(path)\n",
    "    train_dl, test_dl = dataset.split_data()\n",
    "    train_dl = DataLoader(train_dl, batch_size = 32, shuffle = True)\n",
    "    test_dl = DataLoader(test_dl, batch_size = 1024, shuffle = False)\n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_dl):\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optim = SGD(model.parameters(), lr = 0.01, momentum = 0.9)\n",
    "    for epoch in range(600):\n",
    "        for i,(x,y) in enumerate(train_dl):\n",
    "            optim.zero_grad()\n",
    "            yhat = model(x)\n",
    "            loss = criterion(yhat,y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,test_dl):\n",
    "    pred, actuals = list(), list()\n",
    "    for i,(x,y) in enumerate(test_dl):\n",
    "        yhat = model(x)\n",
    "        \n",
    "        yhat = yhat.detach().numpy()\n",
    "        yhat = argmax(yhat,axis = 1)\n",
    "        yhat = yhat.reshape(len(yhat),1)\n",
    "        \n",
    "        actual = y.numpy()\n",
    "        actual = actual.reshape(len(actual),1)\n",
    "        \n",
    "        pred.append(yhat)\n",
    "        actuals.append(y)\n",
    "    pred, actuals = vstack(pred), vstack(actuals)\n",
    "    acc = accuracy_score(actuals,pred)\n",
    "    return acc\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
